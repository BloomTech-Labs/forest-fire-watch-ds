{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, pandas as pd\n",
    "import warnings\n",
    "import psutil, os\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# X_train = pd.read_csv('X_train.csv')\n",
    "# y_train = pd.read_csv('y_train.csv')\n",
    "# X_test = pd.read_csv('X_test.csv')\n",
    "# y_test = pd.read_csv('y_test.csv')\n",
    "\n",
    "# X_train = pd.read_csv('X_train_small.csv')\n",
    "# y_train = pd.read_csv('y_train_small.csv')\n",
    "# X_test = pd.read_csv('X_test_small.csv')\n",
    "# y_test = pd.read_csv('y_test_small.csv')\n",
    "\n",
    "X_train = pd.read_pickle('X_train_full.pkl')\n",
    "y_train = pd.read_pickle('y_train_full.pkl')\n",
    "X_test = pd.read_pickle('X_test_full.pkl')\n",
    "y_test = pd.read_pickle('y_test_full.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting category-encoders\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/a1/f7a22f144f33be78afeb06bfa78478e8284a64263a3c09b1ef54e673841e/category_encoders-2.0.0-py2.py3-none-any.whl (87kB)\n",
      "\u001b[K    100% |████████████████████████████████| 92kB 5.7MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.9.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.20.3)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.5.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (1.1.0)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.24.2)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (1.14.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy>=0.4.1->category-encoders) (1.11.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.21.1->category-encoders) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.21.1->category-encoders) (2.7.3)\n",
      "Installing collected packages: category-encoders\n",
      "Successfully installed category-encoders-2.0.0\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 19.2.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now I'll set up pipelines\n",
    "\n",
    "# scikit-learn pipelines\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# feature processing\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# pre-processing pipeline\n",
    "column_trans = ColumnTransformer(\n",
    "    [('onehot', ce.OneHotEncoder(), ['satellite', 'daynight', 'type']),\n",
    "    ('scale', StandardScaler(), ['brightness', 'track', 'scan', 'acq_time', 'confidence', 'bright_t31', 'frp'])],\n",
    "    remainder='passthrough')\n",
    "\n",
    "# preprocess = make_pipeline(column_trans, FunctionTransformer(all_float_to_int))\n",
    "# # , \n",
    "# #                            FunctionTransformer(downcast_all, \"float\"),\n",
    "# #                           FunctionTransformer(downcast_all, \"integer\"),\n",
    "# #                           FunctionTransformer(downcast_all, target_type = \"unsigned\", \n",
    "# #                            inital_type = \"integer\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 64 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of  30 | elapsed: 18.2min remaining: 163.4min\n",
      "[Parallel(n_jobs=-1)]: Done   7 out of  30 | elapsed: 30.0min remaining: 98.6min\n",
      "[Parallel(n_jobs=-1)]: Done  11 out of  30 | elapsed: 38.0min remaining: 65.6min\n"
     ]
    }
   ],
   "source": [
    "# try to tune RFC with timeseries split\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier \n",
    "\n",
    "random_state = 314\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=3)\n",
    "\n",
    "model =  make_pipeline(column_trans, XGBClassifier(random_state = random_state ))\n",
    "\n",
    "# Create a hyperparameter grid for Gradient Booster\n",
    "\n",
    "xgb_hyperparameters = { \n",
    "    'xgbclassifier__n_estimators' : [100, 200] ,\n",
    "    'xgbclassifier__learning_rate' : [0.05, 0.1, 0.2],\n",
    "    'xgbclassifier__max_depth' : [1, 3, 5] \n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(estimator=model, cv=tscv, scoring='f1',\n",
    "                           param_distributions=rfc_hyperparameters, n_jobs=-1, verbose=10)\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(search.cv_results_).sort_values('mean_test_score', ascending=False)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "y_pred_proba = search.predict_proba(X_test)[:,1]\n",
    "\n",
    "roc_auc_score(y_test, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'rfc_big_fire_training.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
